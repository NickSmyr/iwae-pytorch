{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Env setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0) Create a new Kaggle Dataset with name `ckpts-<EXPERIMENT_DATASET>-<EXPERIMENT_MODEL>-l<EXPERIMENT_L>`\n",
    "e.g.: `chkpts-fashionmnist-iwae-l2` (no `_` allowed)\n",
    "\n",
    "Upload any existing checkpoints there. Then insert this dataset in the current notebook by clicking `+Add data` in the upper right corner. After more checkpoints have been generated, add them to the dataset by navigating to it, then clicking `+ New Version` (in the Data Explorer section of the Data tab) and then adding the new checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Clone GitHub repo\n",
    "Clone achariso/gans-thesis repo into /kaggle/working/code using git clone. For a similar procedure in Colab,\n",
    "see: https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T19:37:58.379240Z",
     "iopub.status.busy": "2022-01-06T19:37:58.378865Z",
     "iopub.status.idle": "2022-01-06T19:38:06.765338Z",
     "shell.execute_reply": "2022-01-06T19:38:06.764408Z",
     "shell.execute_reply.started": "2022-01-06T19:37:58.379183Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clean failed attempts\n",
    "!rm -rf / root /.ssh\n",
    "!rm -rf / kaggle / working / code\n",
    "!mkdir -p / kaggle / working / code\n",
    "\n",
    "git_keys_root = '/kaggle/input/git-keys2'\n",
    "repo_root = '/kaggle/working/code/iwae-pytorch'\n",
    "if not os.path.exists(repo_root):\n",
    "    # Check that ssh keys exist\n",
    "    id_rsa_abs_drive = f'{git_keys_root}/id_rsa'\n",
    "    id_rsa_pub_abs_drive = f'{id_rsa_abs_drive}.pub'\n",
    "    assert os.path.exists(id_rsa_abs_drive)\n",
    "    assert os.path.exists(id_rsa_pub_abs_drive)\n",
    "    # On first run: Add ssh key in repo\n",
    "    if not os.path.exists('/root/.ssh'):\n",
    "        # Transfer config file\n",
    "        ssh_config_abs_drive = f'{git_keys_root}/config'\n",
    "        assert os.path.exists(ssh_config_abs_drive)\n",
    "        !mkdir -p ~ /.ssh\n",
    "        !cp -f \"$ssh_config_abs_drive\" ~ /.ssh /\n",
    "        # Add github.com to known hosts\n",
    "        !ssh-keyscan -t rsa github.com >> ~ /.ssh / known_hosts\n",
    "        # Test ssh connection\n",
    "        # !ssh -T git@github.com\n",
    "\n",
    "    # Remove any previous attempts\n",
    "    !rm -rf \"$repo_root\"\n",
    "    !mkdir -p \"$repo_root\"\n",
    "    # Clone repo\n",
    "    !git clone git @ github.com:kth-ml-course-projects / iwae-pytorch.git \"$repo_root\"\n",
    "\n",
    "    # Fix issue with duplicated files\n",
    "    !rm -rf $repo_root / src-clone / dataloaders\n",
    "    !rm -rf $repo_root / src-clone / utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Install pip packages\n",
    "All required files are stored in a requirements.txt files at the repository's root.\n",
    "Use `pip install -r requirements.txt` from inside the dir to install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T19:38:06.773348Z",
     "iopub.status.busy": "2022-01-06T19:38:06.772918Z",
     "iopub.status.idle": "2022-01-06T19:38:14.195464Z",
     "shell.execute_reply": "2022-01-06T19:38:14.194415Z",
     "shell.execute_reply.started": "2022-01-06T19:38:06.773295Z"
    }
   },
   "outputs": [],
   "source": [
    "% cd \"$repo_root\"\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T19:38:14.197443Z",
     "iopub.status.busy": "2022-01-06T19:38:14.196961Z",
     "iopub.status.idle": "2022-01-06T19:38:14.947523Z",
     "shell.execute_reply": "2022-01-06T19:38:14.946769Z",
     "shell.execute_reply.started": "2022-01-06T19:38:14.197400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Add code/, */src/ to path\n",
    "This is necessary in order to be able to run the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T19:38:14.951744Z",
     "iopub.status.busy": "2022-01-06T19:38:14.949431Z",
     "iopub.status.idle": "2022-01-06T19:38:14.958618Z",
     "shell.execute_reply": "2022-01-06T19:38:14.957291Z",
     "shell.execute_reply.started": "2022-01-06T19:38:14.951712Z"
    }
   },
   "outputs": [],
   "source": [
    "content_root_abs = f'{repo_root}'\n",
    "src_root_abs = f'{repo_root}/src'\n",
    "# %env PYTHONPATH=\"/env/python:$content_root_abs:$src_root_abs\"\n",
    "% set_env PYTHONPATH= / env / python:$content_root_abs:$src_root_abs:$src_clone_root_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Train IWAE model on FashionMNIST Dataset\n",
    "In this section we run the actual training loop for IWAE network. IWAE consists of a 1 or 2 stochastic layer encoder, and a mirrored decoder, where each stochastic layer consists of FC layers with `Tanh()` activations to produce the distribution parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T19:38:14.960483Z",
     "iopub.status.busy": "2022-01-06T19:38:14.959935Z"
    }
   },
   "outputs": [],
   "source": [
    "% cd \"$repo_root/src\"\n",
    "\n",
    "import sys\n",
    "from train import train_and_save_checkpoints\n",
    "from ifaces import DownloadableDataset\n",
    "\n",
    "data_path = '/kaggle/working/data'\n",
    "!mkdir -p $data_path\n",
    "\n",
    "chkpts_dir_path = '/kaggle/working/checkpoints'\n",
    "!mkdir -p $chkpts_dir_path\n",
    "!cp / kaggle / input / chkpts-fashionmnist-iwae-l2 / *.pkl $chkpts_dir_path\n",
    "!ls -l $chkpts_dir_path\n",
    "\n",
    "DownloadableDataset.set_data_directory(data_path)\n",
    "try:\n",
    "    train_and_save_checkpoints(seed=42,\n",
    "                               cuda=True,\n",
    "                               k=5,\n",
    "                               num_layers=2,\n",
    "                               dataset='fashion_mnist',\n",
    "                               model_type='iwae',\n",
    "                               use_clone=True,\n",
    "                               batch_size=400,\n",
    "                               debug=False,\n",
    "                               dtype=torch.float32,\n",
    "                               chkpts_dir_path=chkpts_dir_path,\n",
    "                               use_grad_clip=False)\n",
    "except RuntimeError as e:\n",
    "    print('[EXCEPTION] k=5 FAILed: ' + str(e), file=sys.stderr)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "try:\n",
    "    train_and_save_checkpoints(seed=42,\n",
    "                               cuda=True,\n",
    "                               k=50,\n",
    "                               num_layers=2,\n",
    "                               dataset='fashion_mnist',\n",
    "                               model_type='iwae',\n",
    "                               use_clone=True,\n",
    "                               batch_size=400,\n",
    "                               debug=False,\n",
    "                               dtype=torch.float32,\n",
    "                               chkpts_dir_path=chkpts_dir_path,\n",
    "                               use_grad_clip=False)\n",
    "except RuntimeError as e:\n",
    "    print('[EXCEPTION] k=50 FAILed: ' + str(e), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2) Download checkpoints"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!zip -j chkpts.zip $chkpts_dir_path / *.pkl\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('chkpts.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}